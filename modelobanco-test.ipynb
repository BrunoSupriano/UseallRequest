{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de API Useall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pipeline iniciada em 13/01/2026 16:25:52 ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import urllib.parse\n",
    "import time\n",
    "\n",
    "# --- Configurações ---\n",
    "BASE_URL = \"https://extracao.useallcloud.com.br/api/v1/json/\"\n",
    "HEADERS = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"use-relatorio-token\": \"eyJJZCI6ImNkMDNkMzhiLWZhNzUtNDg4Yi04NDA1LTg5OTU1MzBjNjFiMSIsIlN0cmluZ0NvbmV4YW8iOiJBeHh4IFh2a2VqST10bGRxZGZ4Rzk7c3FJMSBCbz1ScUl4WHlnYWVoO2dNcXp6djFvPXNxSXVleGd5SW5TSSQkOyIsIkNvZGlnb1VzdWFyaW8iOjczMzIsIkNvZGlnb1RlbmFudCI6MTQzfQ==\"\n",
    "}\n",
    "\n",
    "def buscar_dados_api(identificacao, nome_arquivo, backend_filters=None, extra_params=None):\n",
    "    \"\"\"Busca dados na API UseAll e retorna um DataFrame (ou None em caso de erro/vazio)\"\"\"\n",
    "    \n",
    "    query_params = {\"Identificacao\": identificacao}\n",
    "    \n",
    "    if backend_filters:\n",
    "        query_params[\"FiltrosSqlQuery\"] = json.dumps(backend_filters, ensure_ascii=False)\n",
    "        \n",
    "    if extra_params:\n",
    "        query_params.update(extra_params)\n",
    "\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] Iniciando extração: {nome_arquivo}...\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(BASE_URL, headers=HEADERS, params=query_params, timeout=500)\n",
    "            \n",
    "            if response.status_code == 429:\n",
    "                print(f\"[{time.strftime('%H:%M:%S')}] Erro 429 (Too Many Requests) em {nome_arquivo}. Aguardando 185 segundos...\")\n",
    "                time.sleep(185)\n",
    "                continue\n",
    "                \n",
    "            response.raise_for_status()\n",
    "\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data)\n",
    "            return df\n",
    "\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"[{time.strftime('%H:%M:%S')}] Timeout atingido para {nome_arquivo}. Aguardando 185 segundos...\")\n",
    "            time.sleep(185)\n",
    "            continue\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[{time.strftime('%H:%M:%S')}] Erro irrecuperável em {nome_arquivo}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "def salvar_parquet(df, nome_arquivo):\n",
    "    \"\"\"Salva o DataFrame em arquivo parquet\"\"\"\n",
    "    if df is not None and not df.empty:\n",
    "        # Garante extensão .parquet\n",
    "        if not nome_arquivo.endswith('.parquet'):\n",
    "            nome_arquivo += '.parquet'\n",
    "        \n",
    "        try:\n",
    "            df.to_parquet(nome_arquivo, index=False)\n",
    "            print(f\"[{time.strftime('%H:%M:%S')}] Sucesso ao salvar: {nome_arquivo} (Linhas: {len(df)})\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{time.strftime('%H:%M:%S')}] Erro ao salvar {nome_arquivo}: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"[{time.strftime('%H:%M:%S')}] Nada a salvar para {nome_arquivo} (DataFrame vazio ou None)\")\n",
    "\n",
    "def verificar_tipos_dados():\n",
    "    print(\"\\n\" + \"=\" * 40)\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] VERIFICAÇÃO DE TIPOS DE DADOS\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    encontrou = False\n",
    "\n",
    "    for nome, obj in globals().items():\n",
    "        if isinstance(obj, pd.DataFrame):\n",
    "            encontrou = True\n",
    "            print(f\"\\nDataFrame: {nome}\")\n",
    "            if not obj.empty:\n",
    "                print(\"-\" * 30)\n",
    "                print(obj.dtypes)\n",
    "                print(\"-\" * 30)\n",
    "            else:\n",
    "                print(\"  (DataFrame vazio)\")\n",
    "\n",
    "    if not encontrou:\n",
    "        print(\"Nenhum DataFrame encontrado em memória.\")\n",
    "\n",
    "# --- Defines Auxiliares de Filtro ---\n",
    "def filtro_simples(nome, valor):\n",
    "    return {\"Nome\": nome, \"Valor\": valor, \"Operador\": None, \"Descricao\": None, \"ValorFormatado\": None}\n",
    "\n",
    "def carregar_dfs_globais(tarefas):\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] --- INICIANDO CARGA EM MEMÓRIA ---\")\n",
    "\n",
    "    for t in tarefas:\n",
    "        nome = t[\"nome\"]\n",
    "        df = buscar_dados_api(\n",
    "            t[\"id\"],\n",
    "            nome,\n",
    "            t.get(\"filtros\"),\n",
    "            t.get(\"extra_params\")\n",
    "        )\n",
    "\n",
    "        if df is not None:\n",
    "            globals()[nome] = df\n",
    "        else:\n",
    "            print(f\"[{time.strftime('%H:%M:%S')}] Falha ao carregar {nome}\")\n",
    "\n",
    "def carregar_tarefa_complexa(tarefa):\n",
    "    nome = tarefa[\"nome\"]\n",
    "\n",
    "    df = buscar_dados_api(\n",
    "        tarefa[\"id\"],\n",
    "        nome,\n",
    "        tarefa.get(\"filtros\"),\n",
    "        tarefa.get(\"extra_params\")\n",
    "    )\n",
    "\n",
    "    if df is not None:\n",
    "        globals()[nome] = df\n",
    "    else:\n",
    "        print(f\"[{time.strftime('%H:%M:%S')}] Falha ao carregar {nome}\")\n",
    "\n",
    "\n",
    "pipeline_start = time.time()\n",
    "print(f\"--- Pipeline iniciada em {time.strftime('%d/%m/%Y %H:%M:%S')} ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variaveis de filtros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_fixos = {\"pagina\": 1, \"qtderegistros\": 1}\n",
    "\n",
    "tarefas_simples = [\n",
    "    {\n",
    "        \"nome\": \"dfuseallitens\",\n",
    "        \"id\": \"m2_estoque_item\",\n",
    "        \"filtros\": [\n",
    "            filtro_simples(\"DATAHORAALTERACAOINI\", \"01/01/1900\"),\n",
    "            filtro_simples(\"DATAHORAALTERACAOFIM\", \"01/01/2027\")\n",
    "        ],\n",
    "        \"extra_params\": params_fixos\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallunidades\",\n",
    "        \"id\": \"m2_estoque_unidade\",\n",
    "        \"filtros\": [\n",
    "            filtro_simples(\"DATAHORAALTERACAOINI\", \"01/01/1900\"),\n",
    "            filtro_simples(\"DATAHORAALTERACAOFIM\", \"01/01/2027\")\n",
    "        ],\n",
    "        \"extra_params\": params_fixos\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallsegmentos\",\n",
    "        \"id\": \"m2_vendas_segmento\",\n",
    "        \"filtros\": [\n",
    "            filtro_simples(\"DATAHORAALTERACAOINI\", \"01/01/1900\"),\n",
    "            filtro_simples(\"DATAHORAALTERACAOFIM\", \"01/01/2027\")\n",
    "        ],\n",
    "        \"extra_params\": params_fixos\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallcidades\",\n",
    "        \"id\": \"m2_geral_cidades\",\n",
    "        \"filtros\": [\n",
    "            filtro_simples(\"DATAHORAALTERACAOINI\", \"01/01/1900\"),\n",
    "            filtro_simples(\"DATAHORAALTERACAOFIM\", \"01/01/2027\")\n",
    "        ],\n",
    "        \"extra_params\": params_fixos\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallsolcompra\",\n",
    "        \"id\": \"m2_compras_m2_compras_solicitacao_de_compras__extra\",\n",
    "        \"filtros\": [\n",
    "            filtro_simples(\"DATAINI\", \"01/01/1900\"),\n",
    "            filtro_simples(\"DataFim\", \"01/01/2500\")\n",
    "        ],\n",
    "        \"extra_params\": params_fixos\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallfiliais\",\n",
    "        \"id\": \"m2_geral_filiais\",\n",
    "        \"filtros\": [\n",
    "            filtro_simples(\"DATAHORAALTINI\", \"01/01/1900, 11:00:00\"),\n",
    "            filtro_simples(\"DATAHORAALTFIM\", \"01/01/2500, 14:00:00\")\n",
    "        ],\n",
    "        \"extra_params\": params_fixos\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallempresas\",\n",
    "        \"id\": \"m2_geral_empresas\",\n",
    "        \"filtros\": [\n",
    "            filtro_simples(\"DATAHORAALTINI\", \"01/01/2022, 11:00:00\"),\n",
    "            filtro_simples(\"DATAHORAALTFIM\", \"01/01/2027, 14:00:00\")\n",
    "        ],\n",
    "        \"extra_params\": params_fixos\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallexpedição\",\n",
    "        \"id\": \"m2_vendas_extracao_de_dados__saida_expedicao\",\n",
    "        \"filtros\": [\n",
    "            filtro_simples(\"data1\", \"01/01/1900\"),\n",
    "            filtro_simples(\"data2\", \"01/01/2500\")\n",
    "        ],\n",
    "        \"extra_params\": params_fixos\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallclientesfornecedore\",\n",
    "        \"id\": \"m2_geral_clientes__fornecedores\",\n",
    "        \"filtros\": [\n",
    "            filtro_simples(\"DATAHORAALTERACAOINI\", \"01/01/1900\"),\n",
    "            filtro_simples(\"DATAHORAALTERACAOFIM\", \"01/01/2027\")\n",
    "        ],\n",
    "        \"extra_params\": params_fixos\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPLEXAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtros_req = [\n",
    "    {\"Nome\": \"IDFILIAL\", \"Valor\": [333,334,335,336,387,404,520,558,578,339,340,342,343,341,344,345,346,381,389,390], \"Operador\": 1},\n",
    "    {\"Nome\": \"DATA\", \"Valor\": \"01/01/2010,01/01/2027\", \"Operador\": 8, \"TipoPeriodoData\": 5},\n",
    "    {\"Nome\": \"DATAPREVATEND\", \"Valor\": \"01/01/2010,01/01/2027\", \"Operador\": 8, \"TipoPeriodoData\": 8},\n",
    "    {\"Nome\": \"CLASSGRUPOITEM\", \"Valor\": \"\"},\n",
    "    {\"Nome\": \"CLASSCONTACDC\", \"Valor\": \"\"},\n",
    "    {\"Nome\": \"quebra\", \"Valor\": 1},\n",
    "    {\"Nome\": \"FILTROSWHERE\", \"Valor\": \" AND IDEMPRESA = 211\"}\n",
    "]\n",
    "\n",
    "filtros_estoque = [\n",
    "    {\"Nome\": \"ADDATA\", \"Valor\": \"08/01/2010\"},\n",
    "    {\n",
    "        \"Nome\": \"FILTROSWHERE\",\n",
    "        \"Valor\": \" AND EXISTS (SELECT 1 FROM USE_USUARIOS_FILIAIS UFILIAIS \"\n",
    "                \"WHERE UFILIAIS.IDEMPRESA = T.IDEMPRESA \"\n",
    "                \"AND UFILIAIS.IDFILIAL = T.IDFILIAL \"\n",
    "                \"AND UFILIAIS.IDUSUARIO = 7332) \"\n",
    "                \"AND T.IDFILIAL IN (333,334,336,404,335,387,520,558,578)\"\n",
    "    },\n",
    "    {\"Nome\": \"ANQUEBRA\", \"Valor\": 0}\n",
    "]\n",
    "\n",
    "filtros_atend = [\n",
    "    {\n",
    "        \"Nome\": \"FILTROSWHERE\",\n",
    "        \"Valor\": (\n",
    "            \"WHERE IDEMPRESA = 211 \"\n",
    "            \"AND IDFILIAL IN (333,334,335,336,387,404,520,558,339,578,340,342,343,341,344,345,346,381,389,390) \"\n",
    "            \"AND DATA_REQ BETWEEN '01/01/1900' AND '01/01/2900' \"\n",
    "            \"AND DATA_ATEND BETWEEN '01/01/1900' AND '01/01/2900'\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "params_atend = {\n",
    "    \"NomeOrganizacao\": \"SETUP SERVICOS ESPECIALIZADOS LTDA\",\n",
    "    \"Parametros\": json.dumps([\n",
    "        {\"Nome\": \"usecellmerging\", \"Valor\": True},\n",
    "        {\"Nome\": \"quebra\", \"Valor\": 0}\n",
    "    ])\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# BLOCO 1 — REQUISIÇÕES\n",
    "# ===============================\n",
    "\n",
    "tarefa_requisicoes = {\n",
    "    \"nome\": \"dfuseallrequisicoes\",\n",
    "    \"id\": \"m2_estoque_requisicao_de_materiais\",\n",
    "    \"filtros\": filtros_req,\n",
    "    \"extra_params\": None\n",
    "}\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# BLOCO 2 — ESTOQUE\n",
    "# ===============================\n",
    "\n",
    "tarefa_estoque = {\n",
    "    \"nome\": \"dfuseallestoque\",\n",
    "    \"id\": \"09249662000174_m2_estoque_saldo_de_estoque__setup\",\n",
    "    \"filtros\": filtros_estoque,\n",
    "    \"extra_params\": None\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# BLOCO 3 — ATENDIMENTO DE REQUISIÇÕES\n",
    "# ===============================\n",
    "\n",
    "tarefa_atendimento = {\n",
    "    \"nome\": \"dfuseallatendimentodereq\",\n",
    "    \"id\": \"m2_estoque_atendimentos_de_requisicao\",\n",
    "    \"filtros\": filtros_atend,\n",
    "    \"extra_params\": params_atend\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# BLOCO 4 — CUSTOS DE ESTOQUE\n",
    "# ===============================\n",
    "\n",
    "filtros_custos = [\n",
    "    {\"Nome\": \"IDFILIAL\", \"Valor\": [333,334,335,336,387,404,520,558,339,340,341,342,343,344,345,346,381,389,390], \"Operador\": 1},\n",
    "    {\"Nome\": \"FILTROSREGISTROSATIVO\", \"Valor\": \"AND IA.ATIVO = 1 AND I.ATIVO = 1\"},\n",
    "    {\"Nome\": \"DATA\", \"Valor\": \"13/01/2026\"}\n",
    "]\n",
    "\n",
    "params_custos = {\n",
    "    \"Parametros\": [\n",
    "        {\"Nome\": \"usecellmerging\", \"Valor\": True},\n",
    "        {\"Nome\": \"filter\", \"Valor\": (\n",
    "            \"Filiais = SETUP AUTOMACAO E SEGURANCA, LOJA - ARARANGUA, LOJA - CRICIUMA, \"\n",
    "            \"SETUP PELOTAS, SETUP BAHIA, SETUP ELDORADO DO SUL, SETUP BRASILIA, \"\n",
    "            \"SETUP OS\\u00d3RIO, VIGILANCIA SETUP, SETUP FLORIAN\\u00d3POLIS, \"\n",
    "            \"PINHEIRINHO SERVI\\u00c7OS, SETUP COMERCIO MATRIZ, CTFM - ILLUMINATIO ARARANGUA, \"\n",
    "            \"CTFM - ILLUMINATIO CD, VM - DISTRIBUIDORA ARARANGUA MATRIZ, VM - DISTRIBUIDORA CD, \"\n",
    "            \"ENGECO PROJETOS E CONSTRUCOES LTDA, VM - DISTRIBUIDORA CRICIUMA, FFW ADMINISTRADORA DE BENS, \"\n",
    "            \"SETUP LOCA\\u00c7\\u00d5ES; Data = 13/01/2026; Custo = Ambos; \"\n",
    "            \"Apenas itens com saldo = N\\u00e3o; Apenas itens e almoxarifados ativos = Sim\"\n",
    "        )}\n",
    "    ]\n",
    "}\n",
    "\n",
    "tarefa_custos = {\n",
    "    \"nome\": \"dfuseallcustosestoque\",\n",
    "    \"id\": \"m2_estoque_custos\",\n",
    "    \"filtros\": filtros_custos,\n",
    "    \"extra_params\": params_custos\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carregar_dfs_globais(tarefas_simples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carregar_tarefa_complexa(tarefa_estoque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carregar_tarefa_complexa(tarefa_requisicoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:31:46] Iniciando extração: dfuseallcustosestoque...\n",
      "[16:31:47] Erro 429 (Too Many Requests) em dfuseallcustosestoque. Aguardando 185 segundos...\n"
     ]
    }
   ],
   "source": [
    "carregar_tarefa_complexa(tarefa_custos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error: 400 Client Error: Bad Request for url: https://extracao.useallcloud.com.br/api/v1/json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# --- Configurações ---\n",
    "BASE_URL = \"https://extracao.useallcloud.com.br/api/v1/json/\"\n",
    "HEADERS = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"use-relatorio-token\": \"eyJJZCI6ImNkMDNkMzhiLWZhNzUtNDg4Yi04NDA1LTg5OTU1MzBjNjFiMSIsIlN0cmluZ0NvbmV4YW8iOiJBeHh4IFh2a2VqST10bGRxZGZ4Rzk7c3FJMSBCbz1ScUl4WHlnYWVoO2dNcXp6djFvPXNxSXVleGd5SW5TSSQkOyIsIkNvZGlnb1VzdWFyaW8iOjczMzIsIkNvZGlnb1RlbmFudCI6MTQzfQ==\"\n",
    "}\n",
    "# --- Payload direto ---\n",
    "payload = {\n",
    "    \"TipoExportacao\": 2,\n",
    "    \"NomeOrganizacao\": \"SETUP SERVICOS ESPECIALIZADOS LTDA\",\n",
    "    \"Parametros\": [\n",
    "        {\"Nome\": \"usecellmerging\", \"Valor\": True},\n",
    "        {\"Nome\": \"filter\", \"Valor\": (\n",
    "            \"Filiais = SETUP AUTOMACAO E SEGURANCA, LOJA - ARARANGUA, LOJA - CRICIUMA, \"\n",
    "            \"SETUP PELOTAS, SETUP BAHIA, SETUP ELDORADO DO SUL, SETUP BRASILIA, \"\n",
    "            \"SETUP OS\\u00d3RIO, VIGILANCIA SETUP, SETUP FLORIAN\\u00d3POLIS, \"\n",
    "            \"PINHEIRINHO SERVI\\u00c7OS, SETUP COMERCIO MATRIZ, CTFM - ILLUMINATIO ARARANGUA, \"\n",
    "            \"CTFM - ILLUMINATIO CD, VM - DISTRIBUIDORA ARARANGUA MATRIZ, VM - DISTRIBUIDORA CD, \"\n",
    "            \"ENGECO PROJETOS E CONSTRUCOES LTDA, VM - DISTRIBUIDORA CRICIUMA, FFW ADMINISTRADORA DE BENS, \"\n",
    "            \"SETUP LOCA\\u00c7\\u00d5ES; Data = 13/01/2026; Custo = Ambos; \"\n",
    "            \"Apenas itens com saldo = N\\u00e3o; Apenas itens e almoxarifados ativos = Sim\"\n",
    "        )}\n",
    "    ],\n",
    "    \"Identificacao\": \"m2_estoque_custos\",\n",
    "    \"FiltrosSql\": [\n",
    "        {\"Nome\": \"idfilial\", \"Valor\": [333,334,335,336,387,404,520,558,339,340,341,342,343,344,345,346,381,389,390], \"Operador\": 1, \"Descricao\": \"Filial\"},\n",
    "        {\"Nome\": \"FILTROSREGISTROSATIVO\", \"Valor\": \" AND IA.ATIVO = 1 AND I.ATIVO = 1\"},\n",
    "        {\"Nome\": \"data\", \"Valor\": \"13/01/2026\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# --- Requisição POST direta ---\n",
    "try:\n",
    "    response = requests.get(BASE_URL, headers=HEADERS, json=payload, timeout=300)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # --- Converte para DataFrame ---\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    print(df.head())\n",
    "\n",
    "except requests.exceptions.HTTPError as errh:\n",
    "    print(f\"HTTP Error: {errh}\")\n",
    "except requests.exceptions.ConnectionError as errc:\n",
    "    print(f\"Error Connecting: {errc}\")\n",
    "except requests.exceptions.Timeout as errt:\n",
    "    print(f\"Timeout Error: {errt}\")\n",
    "except requests.exceptions.RequestException as err:\n",
    "    print(f\"Erro: {err}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url_completa, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3000\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# --- Converter JSON para DataFrame ---\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\cathe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:667\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m--> 667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# --- URL completa com todos os parâmetros codificados ---\n",
    "url_completa = (\n",
    "    \"https://extracao.useallcloud.com.br/api/v1/json?\"\n",
    "    \"Identificacao=m2_estoque_custos&\"\n",
    "    \"FiltrosSqlQuery=[\"\n",
    "    \"%7B%22Nome%22%3A%22idfilial%22%2C%22Valor%22%3A%5B333%2C334%2C335%2C336%2C520%2C387%2C404%2C558%2C578%2C340%2C341%2C339%2C342%2C343%2C344%2C345%2C346%2C381%2C389%2C390%5D%2C%22Operador%22%3A1%2C%22Descricao%22%3A%22Filial%22%2C%22ValorFormatado%22%3A%22SETUP%20AUTOMACAO%20E%20SEGURANCA%2C%20LOJA%20-%20ARARANGUA%2C%20LOJA%20-%20CRICIUMA%2C%20SETUP%20ELDORADO%20DO%20SUL%2C%20SETUP%20BAHIA%2C%20SETUP%20PELOTAS%2C%20SETUP%20BRASILIA%2C%20SETUP%20OS%C3%93RIO%2C%20VIGILANCIA%20SETUP%2C%20SETUP%20COMERCIO%20MATRIZ%2C%20PINHEIRINHO%20SERVI%C3%87OS%2C%20CTFM%20-%20ILLUMINATIO%20ARARANGUA%2C%20CTFM%20-%20ILLUMINATIO%20CD%2C%20VM%20-%20DISTRIBUIDORA%20ARARANGUA%20MATRIZ%2C%20VM%20-%20DISTRIBUIDORA%20CD%2C%20VM%20-%20DISTRIBUIDORA%20CRICIUMA%2C%20ENGECO%20PROJETOS%20E%20CONSTRUCOES%20LTDA%2C%20FFW%20ADMINISTRADORA%20DE%20BENS%2C%20SETUP%20LOCA%C3%87%C3%95ES%22%2C%22TipoPeriodoData%22%3Anull%7D%2C\"\n",
    "    \"%7B%22Nome%22%3A%22FILTROSREGISTROSATIVO%22%2C%22Valor%22%3A%22%20AND%20IA.ATIVO%20%3D%201%20AND%20I.ATIVO%20%3D%201%22%7D%2C\"\n",
    "    \"%7B%22Nome%22%3A%22filtroswhere%22%2C%22Valor%22%3A%22%20AND%20IDFILIAL%20IN%20(333%2C334%2C335%2C336%2C520%2C387%2C404%2C558%2C578%2C340%2C341%2C339%2C342%2C343%2C344%2C345%2C346%2C381%2C389%2C390)%22%7D%2C\"\n",
    "    \"%7B%22Nome%22%3A%22data%22%2C%22Valor%22%3A%2213/01/2026%22%7D]\"\n",
    ")\n",
    "\n",
    "# --- Headers ---\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"use-relatorio-token\": \"eyJJZCI6ImNkMDNkMzhiLWZhNzUtNDg4Yi04NDA1LTg5OTU1MzBjNjFiMSIsIlN0cmluZ0NvbmV4YW8iOiJBeHh4IFh2a2VqST10bGRxZGZ4Rzk7c3FJMSBCbz1ScUl4WHlnYWVoO2dNcXp6djFvPXNxSXVleGd5SW5TSSQkOyIsIkNvZGlnb1VzdWFyaW8iOjczMzIsIkNvZGlnb1RlbmFudCI6MTQzfQ==\"  # substitua pelo seu token real\n",
    "}\n",
    "\n",
    "# --- Requisição direta ---\n",
    "response = requests.get(url_completa, headers=headers, timeout=3000)\n",
    "\n",
    "# --- Converter JSON para DataFrame ---\n",
    "df = pd.DataFrame(response.json())\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [400]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "https://extracao.useallcloud.com.br/api/v1/json?Identificacao=m2_estoque_custos&FiltrosSqlQuery=[{\"Nome\":\"idfilial\",\"Valor\":[333,334,335,336,520,387,404,558,578,340,341,339,342,343,344,345,346,381,389,390],\"Operador\":1,\"Descricao\":\"Filial\",\"ValorFormatado\":\"SETUP AUTOMACAO E SEGURANCA, LOJA - ARARANGUA, LOJA - CRICIUMA, SETUP ELDORADO DO SUL, SETUP BAHIA, SETUP PELOTAS, SETUP BRASILIA, SETUP OS\\u00d3RIO, SETUP FLORIAN\\u00d3POLIS , VIGILANCIA SETUP, SETUP COMERCIO MATRIZ, PINHEIRINHO SERVI\\u00c7OS, CTFM - ILLUMINATIO ARARANGUA, CTFM - ILLUMINATIO CD, VM - DISTRIBUIDORA ARARANGUA MATRIZ, VM - DISTRIBUIDORA CD, VM - DISTRIBUIDORA CRICIUMA, ENGECO PROJETOS E CONSTRUCOES LTDA, FFW ADMINISTRADORA DE BENS, SETUP LOCA\\u00c7\\u00d5ES\",\"TipoPeriodoData\":null},{\"Nome\":\"FILTROSREGISTROSATIVO\",\"Valor\":\" AND IA.ATIVO = 1 AND I.ATIVO = 1\"},{\"Nome\":\"filtroswhere\",\"Valor\":\" AND IDFILIAL IN (333,334,335,336,520,387,404,558,578,340,341,339,342,343,344,345,346,381,389,390)\"},{\"Nome\":\"data\",\"Valor\":\"13/01/2026\"}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carregar_tarefa_complexa(tarefa_atendimento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando Tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Verificação de Tipos ---\n",
    "print(f\"[{time.strftime('%H:%M:%S')}] --- INICIANDO VERIFICAÇÃO DE TIPOS ---\")\n",
    "verificar_tipos_dados()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurações Banco de Dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "\n",
    "DB_URL = \"postgresql+psycopg2://postgres:4102@localhost:5432/SETUP\"\n",
    "\n",
    "PG_CONN_INFO = {\n",
    "    \"dbname\": \"SETUP\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"4102\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432,\n",
    "}\n",
    "\n",
    "SCHEMA = \"useall\"\n",
    "\n",
    "# ---------------------------------------\n",
    "\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "# garante schema\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {SCHEMA}\"))\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Staging - Bronze - Dados Brutos tipos indefinidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordem_staging = [\n",
    "    # simples iniciais\n",
    "    \"dfuseallitens\",\n",
    "    \"dfuseallunidades\",\n",
    "    \"dfuseallsegmentos\",\n",
    "    \"dfuseallcidades\",\n",
    "\n",
    "    # complexas no meio\n",
    "    \"dfuseallrequisicoes\",\n",
    "    \"dfuseallestoque\",\n",
    "    \"dfuseallatendimentodereq\",\n",
    "\n",
    "    # simples finais\n",
    "    \"dfuseallsolcompra\",\n",
    "    \"dfuseallfiliais\",\n",
    "    \"dfuseallempresas\",\n",
    "    \"dfuseallexpedição\",\n",
    "    \"dfuseallclientesfornecedore\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(msg: str):\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] {msg}\")\n",
    "\n",
    "\n",
    "def copy_df_to_postgres(df, schema: str, table: str):\n",
    "    import psycopg2\n",
    "    import io\n",
    "\n",
    "    buffer = io.StringIO()\n",
    "    df.to_csv(\n",
    "        buffer,\n",
    "        index=False,\n",
    "        header=False,\n",
    "        sep=\"\\t\",\n",
    "        na_rep=\"\\\\N\"\n",
    "    )\n",
    "    buffer.seek(0)\n",
    "\n",
    "    conn = psycopg2.connect(**PG_CONN_INFO)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    sql = f\"\"\"\n",
    "        COPY {schema}.{table}\n",
    "        FROM STDIN\n",
    "        WITH (FORMAT CSV, DELIMITER E'\\t', NULL '\\\\N')\n",
    "    \"\"\"\n",
    "\n",
    "    cur.copy_expert(sql, buffer)\n",
    "\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "tabelas_criadas = 0\n",
    "dfs_nao_encontrados = []\n",
    "\n",
    "log(\"INICIANDO CARGA STAGING (COPY FROM)\")\n",
    "\n",
    "for df_nome in ordem_staging:\n",
    "    df = globals().get(df_nome)\n",
    "\n",
    "    if df is None or df.empty:\n",
    "        dfs_nao_encontrados.append(df_nome)\n",
    "        continue\n",
    "\n",
    "    tabela = \"staging_\" + df_nome.replace(\"dfuseall\", \"\")\n",
    "    tabela = tabela.lower()\n",
    "\n",
    "    log(f\"Preparando tabela {SCHEMA}.{tabela} | Linhas: {len(df)}\")\n",
    "\n",
    "    # 1️⃣ cria estrutura (DDL leve)\n",
    "    with engine.connect() as conn:\n",
    "        df.head(0).to_sql(\n",
    "            name=tabela,\n",
    "            con=conn,\n",
    "            schema=SCHEMA,\n",
    "            if_exists=\"replace\",\n",
    "            index=False\n",
    "        )\n",
    "        conn.commit()\n",
    "\n",
    "    log(f\"Iniciando COPY para {SCHEMA}.{tabela}\")\n",
    "\n",
    "    # 2️⃣ carga pesada via COPY\n",
    "    copy_df_to_postgres(df, SCHEMA, tabela)\n",
    "\n",
    "    log(f\"[OK] Tabela {SCHEMA}.{tabela} carregada com sucesso\")\n",
    "\n",
    "    tabelas_criadas += 1\n",
    "\n",
    "\n",
    "# ---------------- FINAL ----------------\n",
    "\n",
    "log(\"--------------------------------------------------\")\n",
    "\n",
    "if tabelas_criadas == 0:\n",
    "    log(\"Nenhuma tabela staging foi criada.\")\n",
    "    log(\"DataFrames não encontrados:\")\n",
    "    for nome in dfs_nao_encontrados:\n",
    "        log(f\" - {nome}\")\n",
    "else:\n",
    "    log(f\"{tabelas_criadas} tabelas staging criadas com sucesso.\")\n",
    "\n",
    "log(\"PROCESSO FINALIZADO\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silver definindo tipos automaticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA = \"useall\"\n",
    "SAMPLE_LIMIT = 50000\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Detecta formato de data\n",
    "def is_date_series(s: pd.Series):\n",
    "    sample = s.dropna().astype(str).head(50)\n",
    "    formats = [\n",
    "        \"%Y-%m-%d\",\n",
    "        \"%Y-%m-%d %H:%M:%S\",\n",
    "        \"%Y-%m-%dT%H:%M:%S\",\n",
    "        \"%d/%m/%Y\",\n",
    "        \"%d/%m/%Y %H:%M:%S\",\n",
    "    ]\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            pd.to_datetime(sample, format=fmt)\n",
    "            return fmt\n",
    "        except:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "# Inferência de tipo\n",
    "def infer_column_type_final(series: pd.Series) -> dict:\n",
    "    s = series.dropna()\n",
    "    if s.empty:\n",
    "        return {\"type\": \"text\"}\n",
    "\n",
    "    # BOOLEAN lógico\n",
    "    if s.astype(str).isin([\"0\",\"1\",\"true\",\"false\",\"True\",\"False\"]).all():\n",
    "        return {\"type\": \"boolean\"}\n",
    "\n",
    "    # DATE / TIMESTAMP\n",
    "    date_fmt = is_date_series(s)\n",
    "    if date_fmt:\n",
    "        return {\"type\": \"timestamp\", \"format\": date_fmt}\n",
    "\n",
    "    # INTEGER\n",
    "    if s.astype(str).str.fullmatch(r\"-?\\d+\").all():\n",
    "        return {\"type\": \"bigint\"}\n",
    "\n",
    "    # DECIMAL\n",
    "    if s.astype(str).str.fullmatch(r\"-?\\d+(\\.\\d+)?\").all():\n",
    "        return {\"type\": \"numeric(18,4)\"}\n",
    "\n",
    "    return {\"type\": \"text\"}\n",
    "\n",
    "from sqlalchemy import text\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"\"\"\n",
    "        SELECT table_name\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema = :schema\n",
    "          AND table_type = 'BASE TABLE'\n",
    "          AND table_name LIKE 'staging_%'\n",
    "    \"\"\"), {\"schema\": SCHEMA})\n",
    "\n",
    "    staging_tables = [row[0] for row in result.fetchall()]\n",
    "\n",
    "# Função nome silver\n",
    "def silver_table_name(staging_table: str) -> str:\n",
    "    return staging_table.replace(\"staging_\", \"silver_\")\n",
    "\n",
    "# Monta dicionário de metadata\n",
    "schema_silver = {}\n",
    "\n",
    "for staging_table in staging_tables:\n",
    "    if not staging_table.startswith(\"staging_\"):\n",
    "        continue\n",
    "    silver_table = silver_table_name(staging_table)\n",
    "    log(f\"Profiling {SCHEMA}.{staging_table} -> {SCHEMA}.{silver_table}\")\n",
    "\n",
    "    df_sample = pd.read_sql(\n",
    "    f'SELECT * FROM {SCHEMA}.\"{staging_table}\" LIMIT {SAMPLE_LIMIT}',\n",
    "    engine\n",
    "    )\n",
    "\n",
    "    schema_silver[silver_table] = {\n",
    "        \"staging_table\": staging_table,\n",
    "        \"columns\": {\n",
    "            col.lower(): {\n",
    "                **infer_column_type_final(df_sample[col]),\n",
    "                \"source_col\": col  # nome REAL na staging\n",
    "            }\n",
    "            for col in df_sample.columns\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Cria cast SQL\n",
    "def generate_cast_sql(col_dest, meta):\n",
    "    col_src = meta[\"source_col\"]\n",
    "\n",
    "    col_sql = f'\"{col_src}\"'\n",
    "    col_txt = f'{col_sql}::text'\n",
    "\n",
    "    if meta[\"type\"] == \"boolean\":\n",
    "        return f\"\"\"\n",
    "        CASE\n",
    "            WHEN lower({col_txt}) IN ('1','true','sim','s','y','yes') THEN true\n",
    "            WHEN lower({col_txt}) IN ('0','false','nao','n','no') THEN false\n",
    "            ELSE NULL\n",
    "        END AS \"{col_dest}\"\n",
    "        \"\"\"\n",
    "\n",
    "    if meta[\"type\"] == \"timestamp\":\n",
    "        fmt = meta.get(\"format\")\n",
    "        if fmt:\n",
    "            return f\"\"\"\n",
    "            CASE\n",
    "                WHEN {col_txt} = '' THEN NULL\n",
    "                ELSE {col_txt}::{ 'timestamp' if 'H' in fmt else 'date' }\n",
    "            END AS \"{col_dest}\"\n",
    "            \"\"\"\n",
    "        else:\n",
    "            return f\"\"\"\n",
    "            CASE\n",
    "                WHEN {col_sql} IS NULL OR {col_txt} = '' THEN NULL\n",
    "                ELSE {col_sql}::timestamp\n",
    "            END AS \"{col_dest}\"\n",
    "            \"\"\"\n",
    "\n",
    "    if meta[\"type\"] in (\"bigint\",\"numeric(18,4)\"):\n",
    "        return f\"\"\"\n",
    "        CASE\n",
    "            WHEN {col_txt} ~ '^-?\\\\d+(\\\\.\\\\d+)?$' THEN {col_txt}::{meta[\"type\"]}\n",
    "            ELSE NULL\n",
    "        END AS \"{col_dest}\"\n",
    "        \"\"\"\n",
    "\n",
    "    return f'{col_sql}::text AS \"{col_dest}\"'\n",
    "\n",
    "# Gera CREATE TABLE\n",
    "def generate_create_table(schema, table, columns: dict):\n",
    "    cols = \",\\n  \".join(f'\"{col_dest}\" {meta[\"type\"]}' for col_dest, meta in columns.items())\n",
    "    return f\"\"\"\n",
    "    DROP TABLE IF EXISTS {schema}.\"{table}\";\n",
    "    CREATE TABLE {schema}.\"{table}\" (\n",
    "      {cols}\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "# Cria tabelas silver\n",
    "for silver_table, meta in schema_silver.items():\n",
    "    log(f\"Criando tabela silver {SCHEMA}.{silver_table}\")\n",
    "    ddl = generate_create_table(SCHEMA, silver_table, meta[\"columns\"])\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(ddl))\n",
    "\n",
    "# Gera INSERT\n",
    "def generate_insert_cast(staging_schema, SCHEMA, staging_table, silver_table, columns):\n",
    "    selects = \",\\n\".join(generate_cast_sql(col_dest, meta) for col_dest, meta in columns.items())\n",
    "    return f\"\"\"\n",
    "    INSERT INTO {SCHEMA}.\"{silver_table}\"\n",
    "    SELECT\n",
    "      {selects}\n",
    "    FROM {staging_schema}.\"{staging_table}\";\n",
    "    \"\"\"\n",
    "\n",
    "# Carrega dados\n",
    "for silver_table, meta in schema_silver.items():\n",
    "    staging_table = meta[\"staging_table\"]\n",
    "    columns = meta[\"columns\"]\n",
    "    log(f\"Carregando dados em {SCHEMA}.{silver_table}\")\n",
    "    sql = generate_insert_cast(SCHEMA, SCHEMA, staging_table, silver_table, columns)\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            conn.execute(text(sql))\n",
    "        log(f\"[OK] {SCHEMA}.{silver_table} carregada\")\n",
    "    except Exception as e:\n",
    "        log(f\"[ERRO] {SCHEMA}.{silver_table} -> {e}\")\n",
    "\n",
    "log(\"--------------------------------------------------\")\n",
    "log(\"PROCESSO FINALIZADO\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold - Adicionando novas colunas e agregando valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "sql = \"\"\"\n",
    "DO $$\n",
    "DECLARE\n",
    "    r RECORD;\n",
    "    gold_table TEXT;\n",
    "BEGIN\n",
    "    FOR r IN\n",
    "        SELECT table_name\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema = 'useall'\n",
    "          AND table_name LIKE 'silver_%'\n",
    "    LOOP\n",
    "\n",
    "        gold_table := replace(r.table_name, 'silver_', 'gold_');\n",
    "\n",
    "        -- CASO ESPECIAL: SILVER_REQUISICOES\n",
    "        IF r.table_name = 'silver_requisicoes' THEN\n",
    "\n",
    "            -- cria se não existir\n",
    "            EXECUTE format(\n",
    "                'CREATE TABLE IF NOT EXISTS useall.%I AS\n",
    "                 SELECT\n",
    "                     *,\n",
    "                     CASE status::int\n",
    "                         WHEN 0  THEN ''Digitado''\n",
    "                         WHEN 1  THEN ''Aberto''\n",
    "                         WHEN 3  THEN ''Cancelado''\n",
    "                         WHEN 10 THEN ''Parcial''\n",
    "                         WHEN 11 THEN ''Atendido''\n",
    "                         ELSE ''Desconhecido''\n",
    "                     END AS py_desc_status\n",
    "                 FROM useall.silver_requisicoes\n",
    "                 WHERE false;',\n",
    "                gold_table\n",
    "            );\n",
    "\n",
    "            -- limpa e reinsere\n",
    "            EXECUTE format('TRUNCATE TABLE useall.%I;', gold_table);\n",
    "\n",
    "            EXECUTE format(\n",
    "                'INSERT INTO useall.%I\n",
    "                 SELECT\n",
    "                     *,\n",
    "                     CASE status::int\n",
    "                         WHEN 0  THEN ''Digitado''\n",
    "                         WHEN 1  THEN ''Aberto''\n",
    "                         WHEN 3  THEN ''Cancelado''\n",
    "                         WHEN 10 THEN ''Parcial''\n",
    "                         WHEN 11 THEN ''Atendido''\n",
    "                         ELSE ''Desconhecido''\n",
    "                     END AS py_desc_status\n",
    "                 FROM useall.silver_requisicoes;',\n",
    "                gold_table\n",
    "            );\n",
    "\n",
    "        -- DEMAIS TABELAS\n",
    "        ELSE\n",
    "\n",
    "            -- cria se não existir\n",
    "            EXECUTE format(\n",
    "                'CREATE TABLE IF NOT EXISTS useall.%I AS\n",
    "                 SELECT * FROM useall.%I WHERE false;',\n",
    "                gold_table,\n",
    "                r.table_name\n",
    "            );\n",
    "\n",
    "            -- limpa e reinsere\n",
    "            EXECUTE format('TRUNCATE TABLE useall.%I;', gold_table);\n",
    "\n",
    "            EXECUTE format(\n",
    "                'INSERT INTO useall.%I\n",
    "                 SELECT * FROM useall.%I;',\n",
    "                gold_table,\n",
    "                r.table_name\n",
    "            );\n",
    "\n",
    "        END IF;\n",
    "\n",
    "    END LOOP;\n",
    "END $$;\n",
    "\"\"\"\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(sql))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
