{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pipeline iniciada em 13/01/2026 08:06:44 ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import urllib.parse\n",
    "import time\n",
    "\n",
    "# --- Configurações ---\n",
    "BASE_URL = \"https://extracao.useallcloud.com.br/api/v1/json/\"\n",
    "HEADERS = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"use-relatorio-token\": \"eyJJZCI6ImNkMDNkMzhiLWZhNzUtNDg4Yi04NDA1LTg5OTU1MzBjNjFiMSIsIlN0cmluZ0NvbmV4YW8iOiJBeHh4IFh2a2VqST10bGRxZGZ4Rzk7c3FJMSBCbz1ScUl4WHlnYWVoO2dNcXp6djFvPXNxSXVleGd5SW5TSSQkOyIsIkNvZGlnb1VzdWFyaW8iOjczMzIsIkNvZGlnb1RlbmFudCI6MTQzfQ==\"\n",
    "}\n",
    "\n",
    "def buscar_dados_api(identificacao, nome_arquivo, backend_filters=None, extra_params=None):\n",
    "    \"\"\"Busca dados na API UseAll e retorna um DataFrame (ou None em caso de erro/vazio)\"\"\"\n",
    "    \n",
    "    query_params = {\"Identificacao\": identificacao}\n",
    "    \n",
    "    if backend_filters:\n",
    "        query_params[\"FiltrosSqlQuery\"] = json.dumps(backend_filters, ensure_ascii=False)\n",
    "        \n",
    "    if extra_params:\n",
    "        query_params.update(extra_params)\n",
    "\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] Iniciando extração: {nome_arquivo}...\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(BASE_URL, headers=HEADERS, params=query_params, timeout=500)\n",
    "            \n",
    "            if response.status_code == 429:\n",
    "                print(f\"[{time.strftime('%H:%M:%S')}] Erro 429 (Too Many Requests) em {nome_arquivo}. Aguardando 185 segundos...\")\n",
    "                time.sleep(185)\n",
    "                continue\n",
    "                \n",
    "            response.raise_for_status()\n",
    "\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data)\n",
    "            return df\n",
    "\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"[{time.strftime('%H:%M:%S')}] Timeout atingido para {nome_arquivo}. Aguardando 185 segundos...\")\n",
    "            time.sleep(185)\n",
    "            continue\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[{time.strftime('%H:%M:%S')}] Erro irrecuperável em {nome_arquivo}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "def salvar_parquet(df, nome_arquivo):\n",
    "    \"\"\"Salva o DataFrame em arquivo parquet\"\"\"\n",
    "    if df is not None and not df.empty:\n",
    "        # Garante extensão .parquet\n",
    "        if not nome_arquivo.endswith('.parquet'):\n",
    "            nome_arquivo += '.parquet'\n",
    "        \n",
    "        try:\n",
    "            df.to_parquet(nome_arquivo, index=False)\n",
    "            print(f\"[{time.strftime('%H:%M:%S')}] Sucesso ao salvar: {nome_arquivo} (Linhas: {len(df)})\")\n",
    "        except Exception as e:\n",
    "             print(f\"[{time.strftime('%H:%M:%S')}] Erro ao salvar {nome_arquivo}: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"[{time.strftime('%H:%M:%S')}] Nada a salvar para {nome_arquivo} (DataFrame vazio ou None)\")\n",
    "\n",
    "def verificar_tipos_dados(dfs_dict):\n",
    "    \"\"\"Exibe os tipos de dados (dtypes) de cada DataFrame no dicionário\"\"\"\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] VERIFICAÇÃO DE TIPOS DE DADOS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    for nome, df in dfs_dict.items():\n",
    "        print(f\"\\nDataFrame: {nome}\")\n",
    "        if df is not None and not df.empty:\n",
    "            print(\"-\" * 30)\n",
    "            print(df.dtypes)\n",
    "            print(\"-\" * 30)\n",
    "        else:\n",
    "             print(\"  (Vazio ou não carregado)\")\n",
    "\n",
    "# --- Defines Auxiliares de Filtro ---\n",
    "def filtro_simples(nome, valor):\n",
    "    return {\"Nome\": nome, \"Valor\": valor, \"Operador\": None, \"Descricao\": None, \"ValorFormatado\": None}\n",
    "\n",
    "pipeline_start = time.time()\n",
    "print(f\"--- Pipeline iniciada em {time.strftime('%d/%m/%Y %H:%M:%S')} ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Definição dos Filtros Complexos ---\n",
    "\n",
    "filtros_req = [\n",
    "    {\"Nome\": \"IDFILIAL\", \"Valor\": [333,334,335,336,387,404,520,558,578,339,340,342,343,341,344,345,346,381,389,390], \"Operador\": 1, \"Descricao\": \"Filial\", \"ValorFormatado\": \"SETUP AUTOMACAO E SEGURANCA\", \"TipoPeriodoData\": None},\n",
    "    {\"Nome\": \"DATA\", \"Valor\": \"01/01/1900,01/01/2027\", \"Operador\": 8, \"Descricao\": \"Data da requisição\", \"ValorFormatado\": \"01/01/1900 até 01/01/2027\", \"TipoPeriodoData\": 14},\n",
    "    {\"Nome\": \"DATAPREVATEND\", \"Valor\": \"01/01/1900,01/01/2027\", \"Operador\": 8, \"Descricao\": \"Previsão atendimento\", \"ValorFormatado\": \"01/01/1900 até 01/01/2027\", \"TipoPeriodoData\": 14},\n",
    "    {\"Nome\": \"CLASSGRUPOITEM\", \"Valor\": \"\"},\n",
    "    {\"Nome\": \"CLASSCONTACDC\", \"Valor\": \"\"},\n",
    "    {\"Nome\": \"quebra\", \"Valor\": 0},\n",
    "    {\"Nome\": \"FILTROSWHERE\", \"Valor\": \" AND IDEMPRESA = 211\"}\n",
    "]\n",
    "\n",
    "filtros_estoque = [\n",
    "    {\"Nome\": \"ADDATA\", \"Valor\": \"08/01/2026\"},\n",
    "    {\"Nome\": \"FILTROSWHERE\", \"Valor\": \" AND EXISTS (SELECT 1 FROM USE_USUARIOS_FILIAIS UFILIAIS WHERE UFILIAIS.IDEMPRESA = T.IDEMPRESA AND UFILIAIS.IDFILIAL = T.IDFILIAL AND UFILIAIS.IDUSUARIO = 7332) AND T.IDFILIAL IN (333,334,336,404,335,387,520,558,578)\"},\n",
    "    {\"Nome\": \"ANQUEBRA\", \"Valor\": 0}\n",
    "]\n",
    "\n",
    "filtros_atend = [{\"Nome\": \"FILTROSWHERE\", \"Valor\": \"WHERE IDEMPRESA = 211 AND IDFILIAL IN (333,334,335,336,387,404,520,558,339,578,340,342,343,341,344,345,346,381,389,390) AND DATA_REQ >= '01/01/1900' AND DATA_REQ <= '01/01/2900' AND DATA_ATEND >= '01/01/1900' AND DATA_ATEND <= '01/01/2900'\"}]\n",
    "\n",
    "params_atend = {\n",
    "    \"NomeOrganizacao\": \"SETUP SERVICOS ESPECIALIZADOS LTDA\",\n",
    "    \"Parametros\": json.dumps([\n",
    "        {\"Nome\": \"usecellmerging\", \"Valor\": True},\n",
    "        {\"Nome\": \"quebra\", \"Valor\": 0},\n",
    "        {\"Nome\": \"filter\", \"Valor\": \"Filial: SETUP AUTOMACAO E SEGURANCA, LOJA - ARARANGUA, LOJA - CRICIUMA\\nData requisição: 01/01/1900 até 01/01/2900\\nData atendimento: 01/01/1900 até 01/01/2900\"}\n",
    "    ])\n",
    "}\n",
    "\n",
    "# --- Lista Unificada de Tarefas ---\n",
    "\n",
    "params_fixos = {\"pagina\": 1, \"qtderegistros\": 1}\n",
    "\n",
    "tarefas = [\n",
    "    # Simples\n",
    "    {\n",
    "        \"nome\": \"dfuseallitens\",\n",
    "        \"id\": \"m2_estoque_item\",\n",
    "        \"filtros\": [filtro_simples(\"DATAHORAALTERACAOINI\", \"01/01/1900\"), filtro_simples(\"DATAHORAALTERACAOFIM\", \"01/01/2027\")],\n",
    "        \"extra_params\": params_fixos\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallunidades\",\n",
    "        \"id\": \"m2_estoque_unidade\",\n",
    "        \"filtros\": [filtro_simples(\"DATAHORAALTERACAOINI\", \"01/01/1900\"), filtro_simples(\"DATAHORAALTERACAOFIM\", \"01/01/2027\")],\n",
    "        \"extra_params\": params_fixos\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallsegmentos\",\n",
    "        \"id\": \"m2_vendas_segmento\",\n",
    "        \"filtros\": [filtro_simples(\"DATAHORAALTERACAOINI\", \"01/01/1900\"), filtro_simples(\"DATAHORAALTERACAOFIM\", \"01/01/2027\")],\n",
    "        \"extra_params\": params_fixos\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallcidades\",\n",
    "        \"id\": \"m2_geral_cidades\",\n",
    "        \"filtros\": [filtro_simples(\"DATAHORAALTERACAOINI\", \"01/01/1900\"), filtro_simples(\"DATAHORAALTERACAOFIM\", \"01/01/2027\")],\n",
    "        \"extra_params\": params_fixos\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallsolcompra\",\n",
    "        \"id\": \"m2_compras_m2_compras_solicitacao_de_compras__extra\",\n",
    "        \"filtros\": [filtro_simples(\"DataFim\", \"01/01/2500\"), filtro_simples(\"DATAINI\", \"01/01/1900\")],\n",
    "        \"extra_params\": params_fixos\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallfiliais\",\n",
    "        \"id\": \"m2_geral_filiais\",\n",
    "        \"filtros\": [filtro_simples(\"DATAHORAALTINI\", \"01/01/1900, 11:00:00\"), filtro_simples(\"DATAHORAALTFIM\", \"01/01/2500, 14:00:00\")],\n",
    "        \"extra_params\": params_fixos\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallempresas\",\n",
    "        \"id\": \"m2_geral_empresas\",\n",
    "        \"filtros\": [filtro_simples(\"DATAHORAALTINI\", \"01/01/2022, 11:00:00\"), filtro_simples(\"DATAHORAALTFIM\", \"01/01/2027, 14:00:00\")],\n",
    "        \"extra_params\": params_fixos\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallexpedição\",\n",
    "        \"id\": \"m2_vendas_extracao_de_dados__saida_expedicao\",\n",
    "        \"filtros\": [filtro_simples(\"data1\", \"01/01/1900\"), filtro_simples(\"data2\", \"01/01/2500\")],\n",
    "        \"extra_params\": params_fixos\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallclientesfornecedore\",\n",
    "        \"id\": \"m2_geral_clientes__fornecedores\",\n",
    "        \"filtros\": [filtro_simples(\"DATAHORAALTERACAOINI\", \"01/01/1900\"), filtro_simples(\"DATAHORAALTERACAOFIM\", \"01/01/2027\")],\n",
    "        \"extra_params\": params_fixos\n",
    "    },\n",
    "    # Complexas\n",
    "    {\n",
    "        \"nome\": \"dfuseallrequisicoes\",\n",
    "        \"id\": \"m2_estoque_requisicao_de_materiais\",\n",
    "        \"filtros\": filtros_req,\n",
    "        \"extra_params\": None\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallestoque\",\n",
    "        \"id\": \"09249662000174_m2_estoque_saldo_de_estoque__setup\",\n",
    "        \"filtros\": filtros_estoque,\n",
    "        \"extra_params\": None\n",
    "    },\n",
    "    {\n",
    "        \"nome\": \"dfuseallatendimentodereq\",\n",
    "        \"id\": \"m2_estoque_atendimentos_de_requisicao\",\n",
    "        \"filtros\": filtros_atend,\n",
    "        \"extra_params\": params_atend\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:28:59] --- INICIANDO CARGA EM MEMÓRIA ---\n",
      "[09:28:59] Iniciando extração: dfuseallitens...\n",
      "[09:29:02] Iniciando extração: dfuseallunidades...\n",
      "[09:29:03] Iniciando extração: dfuseallsegmentos...\n",
      "[09:29:04] Iniciando extração: dfuseallcidades...\n",
      "[09:29:06] Iniciando extração: dfuseallsolcompra...\n",
      "[09:29:07] Iniciando extração: dfuseallfiliais...\n",
      "[09:29:08] Iniciando extração: dfuseallempresas...\n",
      "[09:29:09] Iniciando extração: dfuseallexpedição...\n",
      "[09:29:23] Iniciando extração: dfuseallclientesfornecedore...\n",
      "[09:29:31] Iniciando extração: dfuseallrequisicoes...\n",
      "[09:31:10] Iniciando extração: dfuseallestoque...\n",
      "[09:31:52] Iniciando extração: dfuseallatendimentodereq...\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Carregamento dos DataFrames (Memória) ---\n",
    "dfs_carregados = {}\n",
    "\n",
    "print(f\"[{time.strftime('%H:%M:%S')}] --- INICIANDO CARGA EM MEMÓRIA ---\")\n",
    "\n",
    "for t in tarefas:\n",
    "    df = buscar_dados_api(t[\"id\"], t[\"nome\"], t.get(\"filtros\"), t.get(\"extra_params\"))\n",
    "    \n",
    "    if df is not None:\n",
    "        dfs_carregados[t[\"nome\"]] = df\n",
    "    else:\n",
    "        print(f\"[{time.strftime('%H:%M:%S')}] Falha ao carregar {t['nome']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:37:31] --- INICIANDO VERIFICAÇÃO DE TIPOS ---\n",
      "\n",
      "========================================\n",
      "[09:37:31] VERIFICAÇÃO DE TIPOS DE DADOS\n",
      "========================================\n",
      "\n",
      "DataFrame: dfuseallitens\n",
      "------------------------------\n",
      "IDITEM                 int64\n",
      "DATAHORAALTERACAO     object\n",
      "IDENTIFICACAO         object\n",
      "DESCRICAO             object\n",
      "IDCLASSFISCAL          int64\n",
      "IDUN                   int64\n",
      "IDUNVENDA            float64\n",
      "QUANTEMBVENDA        float64\n",
      "PESOBRUTO            float64\n",
      "PESOLIQ              float64\n",
      "OBS                   object\n",
      "ATIVO                  int64\n",
      "COMPLEMENTO           object\n",
      "IDGRUPOITEM          float64\n",
      "IDTIPOITEM             int64\n",
      "QUANTMINVENDA        float64\n",
      "CODBARRA              object\n",
      "LIBERADO              object\n",
      "FORMATOCODBAR        float64\n",
      "dtype: object\n",
      "------------------------------\n",
      "\n",
      "DataFrame: dfuseallunidades\n",
      "------------------------------\n",
      "IDUN                  int64\n",
      "IDUNIDADETENANT       int64\n",
      "DESCRICAO            object\n",
      "SIGLA                object\n",
      "SIGLAFCI             object\n",
      "DATAHORAALTERACAO    object\n",
      "STATUS               object\n",
      "dtype: object\n",
      "------------------------------\n",
      "\n",
      "DataFrame: dfuseallsegmentos\n",
      "  (Vazio ou não carregado)\n",
      "\n",
      "DataFrame: dfuseallcidades\n",
      "------------------------------\n",
      "IDCIDADE               int64\n",
      "DATAHORAALTERACAO     object\n",
      "NOME                  object\n",
      "MUNICIPIO_IBGE         int64\n",
      "IDNFSE               float64\n",
      "CODIGORFB            float64\n",
      "DATAHORACAD           object\n",
      "CODIBGE                int64\n",
      "SIGLA                 object\n",
      "dtype: object\n",
      "------------------------------\n",
      "\n",
      "DataFrame: dfuseallsolcompra\n",
      "------------------------------\n",
      "IDSOLICCOMPRA                int64\n",
      "IDEMPRESA                    int64\n",
      "IDFILIAL                     int64\n",
      "NUMERO                       int64\n",
      "IDSOLICITANTE                int64\n",
      "OBS                         object\n",
      "STATUS                      object\n",
      "PRIMEIRADATANECESSIDADE     object\n",
      "FINALIDADE                  object\n",
      "IDSOLICCOMPRAITEM            int64\n",
      "IDENTIFICACAO               object\n",
      "IDUN                         int64\n",
      "QUANT                      float64\n",
      "DATANECESSIDADE             object\n",
      "COMPLEMENTO                 object\n",
      "SALDO                      float64\n",
      "URGENTE                      int64\n",
      "URGENTE_DESC                object\n",
      "IDCONTACDC                 float64\n",
      "CLASSIFICACAO               object\n",
      "DESCRICAO                   object\n",
      "dtype: object\n",
      "------------------------------\n",
      "\n",
      "DataFrame: dfuseallfiliais\n",
      "------------------------------\n",
      "IDFILIAL        int64\n",
      "DATAHORAALT    object\n",
      "IDEMPRESA       int64\n",
      "MATRIZ          int64\n",
      "APELIDO        object\n",
      "dtype: object\n",
      "------------------------------\n",
      "\n",
      "DataFrame: dfuseallempresas\n",
      "------------------------------\n",
      "IDEMPRESA        int64\n",
      "DATAHORAALT     object\n",
      "CNPJCPF         object\n",
      "RAZAOSOCIAL     object\n",
      "NOMEFANTASIA    object\n",
      "IE              object\n",
      "IM              object\n",
      "ENDERECO        object\n",
      "BAIRRO          object\n",
      "CEP             object\n",
      "FONE            object\n",
      "FAX             object\n",
      "EMAIL           object\n",
      "IDCIDADE         int64\n",
      "dtype: object\n",
      "------------------------------\n",
      "\n",
      "DataFrame: dfuseallexpedição\n",
      "------------------------------\n",
      "CODIGOFAT                       int64\n",
      "DATAHORACAD                    object\n",
      "DATAENTREGA                    object\n",
      "CONFERENCIA                    object\n",
      "ORIGEMCONFERENCIA             float64\n",
      "DESCRICAOORIGEMCONFERENCIA     object\n",
      "ORIGEM                         object\n",
      "CODIGOOIRIGEM                   int64\n",
      "NUMERODOC                       int64\n",
      "NUMEROPEDIDOCLIENTE            object\n",
      "CODIGOCLIENTE                 float64\n",
      "RAZAOCLIENTE                   object\n",
      "ENDERECO                       object\n",
      "CEP                            object\n",
      "CIDADE                         object\n",
      "UF                             object\n",
      "ENDERECOENTREGA                object\n",
      "CEPENTREGA                     object\n",
      "CIDADEENTREGA                  object\n",
      "UFENTREGA                      object\n",
      "CODIGOTRANSP                  float64\n",
      "RAZAOTRANSP                    object\n",
      "RAWTOGUID(GUIDLOTE)            object\n",
      "CARGA                          object\n",
      "CODIGOUSUARIO                 float64\n",
      "NOMEUSUARIO                    object\n",
      "CODIGOGRUPOEMPRESARIAL        float64\n",
      "DESCRICAOGRUPOEMPRESARIAL      object\n",
      "NUMEROITEMPEDIDOCLIENTE        object\n",
      "SEQ                             int64\n",
      "IDENTIFICACAO                  object\n",
      "DESCRICAO                      object\n",
      "UNIDADE                        object\n",
      "QUANTSELECIONADA              float64\n",
      "QUANTCONFERIDA                float64\n",
      "SALDO                         float64\n",
      "ORDEM                           int64\n",
      "CODIGOFILIAL                    int64\n",
      "CODIGOEMPRESA                   int64\n",
      "PLACA                          object\n",
      "ORDEMENTREGA                   object\n",
      "DATAPREVCARREG                 object\n",
      "STATUSCONF                      int64\n",
      "CODIGOTRANSPTENANT            float64\n",
      "DATAHORAPREPARACAO             object\n",
      "IDPEDITEM                       int64\n",
      "dtype: object\n",
      "------------------------------\n",
      "\n",
      "DataFrame: dfuseallclientesfornecedore\n",
      "------------------------------\n",
      "IDCLIFOREMP                 int64\n",
      "DATAHORAALTERACAO          object\n",
      "IDCLIFOREMPTENANT           int64\n",
      "DATAHORACAD                object\n",
      "NOMEFANTASIA               object\n",
      "RAZAOSOCIAL                object\n",
      "CNPJCPF                    object\n",
      "FONE                       object\n",
      "EMAIL                      object\n",
      "IE                         object\n",
      "RG                         object\n",
      "OBS                        object\n",
      "ISUFRAMA                   object\n",
      "ATIVO                       int64\n",
      "CONTRIBICMS                 int64\n",
      "IDTRANSP                  float64\n",
      "CEP                        object\n",
      "IDCIDADE                    int64\n",
      "ENDERECO                   object\n",
      "NUMENDERECO                object\n",
      "BAIRRO                     object\n",
      "COMPLENDERECO              object\n",
      "CEPENT                     object\n",
      "IDCIDADEENT                 int64\n",
      "ENDERECOENT                object\n",
      "NUMENDERECOENT             object\n",
      "BAIRROENT                  object\n",
      "COMPLENDERECOENT           object\n",
      "CEPCOB                     object\n",
      "IDCIDADECOB                 int64\n",
      "ENDERECOCOB                object\n",
      "NUMENDERECOCOB             object\n",
      "BAIRROCOB                  object\n",
      "COMPLENDERECOCOB           object\n",
      "LATITUDE                  float64\n",
      "LONGITUDE                 float64\n",
      "DATALIMCREDITO             object\n",
      "VALORLIMCREDITO           float64\n",
      "IDRISCOCREDITO            float64\n",
      "IDTABPRECOVENDA           float64\n",
      "IDCONDPAGTO               float64\n",
      "IDFORMAPAGTO              float64\n",
      "IDVENDEDOR                float64\n",
      "IDSUPERVISOR              float64\n",
      "SEGMENTO                   object\n",
      "IDPAIS                      int64\n",
      "CLIENTE                    object\n",
      "EMPREGADO                  object\n",
      "FORNECEDOR                 object\n",
      "VENDEDOR_REPRESENTANTE     object\n",
      "TRANSPORTADOR              object\n",
      "TIPOPESSOA                 object\n",
      "REGIMETRIB                 object\n",
      "TIPOFRETE                  object\n",
      "dtype: object\n",
      "------------------------------\n",
      "\n",
      "DataFrame: dfuseallrequisicoes\n",
      "------------------------------\n",
      "DESC_FILIAL                object\n",
      "ENDERECO_FILIAL            object\n",
      "CEP_FILIAL                 object\n",
      "FAX_FILIAL                 object\n",
      "FONE_FILIAL                object\n",
      "CPF_CNPJ_FILIAL            object\n",
      "INSC_ESTADUAL_FILIAL       object\n",
      "CIDADE_FILIAL              object\n",
      "UF_FILIAL                  object\n",
      "IDEMPRESA                   int64\n",
      "IDFILIAL                    int64\n",
      "IDREQMAT                    int64\n",
      "IDREQMATTENANT              int64\n",
      "DATA                       object\n",
      "DATAPREVATEND              object\n",
      "IDALMOX                     int64\n",
      "STATUS                      int64\n",
      "TIPO                        int64\n",
      "DESC_ALMOX                 object\n",
      "SIGLA_ALMOX                object\n",
      "IDTENANT                    int64\n",
      "IDREQMATITEM                int64\n",
      "QUANT                     float64\n",
      "QUANTCANCEL               float64\n",
      "QUANTATEND                float64\n",
      "QUANTSUBST                float64\n",
      "SALDO                     float64\n",
      "IDREQUISITANTE            float64\n",
      "REQUISITANTE               object\n",
      "SIGLA_UN                   object\n",
      "IDITEM                      int64\n",
      "IDENTIFICACAO              object\n",
      "DESCRICAO                  object\n",
      "IDGRUPOITEM                 int64\n",
      "IDCONTACDC                float64\n",
      "CLASSIFICACAOGRUPOITEM     object\n",
      "DESC_GRUPO                 object\n",
      "DESCRICAOCONTACDC          object\n",
      "CLASSIFICACAOCONTACDC      object\n",
      "dtype: object\n",
      "------------------------------\n",
      "\n",
      "DataFrame: dfuseallestoque\n",
      "------------------------------\n",
      "IDSECAO            float64\n",
      "IDFILIAL             int64\n",
      "IDEMPRESA            int64\n",
      "IDALMOX              int64\n",
      "TIPOALMOX            int64\n",
      "DESC_ALMOX          object\n",
      "IDUN                 int64\n",
      "IDITEM               int64\n",
      "IDENTIFICACAO       object\n",
      "DESC_ITEM           object\n",
      "IDMARCA            float64\n",
      "IDTIPOITEM           int64\n",
      "IDGRUPOITEM          int64\n",
      "CLASSIFICACAO       object\n",
      "DESC_GRUPO          object\n",
      "DESC_MARCA          object\n",
      "SALDOFISICO        float64\n",
      "QUANTRESERVADA     float64\n",
      "SALDODISPONIVEL    float64\n",
      "ESTOQUEMIN         float64\n",
      "ESTOQUEMAX         float64\n",
      "DESC_TIPOITEM       object\n",
      "SIGLA               object\n",
      "POSICAO            float64\n",
      "dtype: object\n",
      "------------------------------\n",
      "\n",
      "DataFrame: dfuseallatendimentodereq\n",
      "------------------------------\n",
      "DESC_FILIAL              object\n",
      "ENDERECO_FILIAL          object\n",
      "CEP_FILIAL               object\n",
      "FAX_FILIAL               object\n",
      "FONE_FILIAL              object\n",
      "CPF_CNPJ_FILIAL          object\n",
      "INSC_ESTADUAL_FILIAL     object\n",
      "CIDADE_FILIAL            object\n",
      "UF_FILIAL                object\n",
      "DATA_ATEND               object\n",
      "IDEMPREGADO_ATEND         int64\n",
      "QUANT_ATEND             float64\n",
      "IDEMPRESA                 int64\n",
      "IDFILIAL                  int64\n",
      "IDREQMAT                  int64\n",
      "NUMEROOS                 object\n",
      "NUMEROPROCSERV          float64\n",
      "NUMEROOP                 object\n",
      "DATA_REQ                 object\n",
      "IDALMOX                   int64\n",
      "TIPO                      int64\n",
      "DESC_ALMOX               object\n",
      "IDREQUISITANTE          float64\n",
      "REQUISITANTE             object\n",
      "SIGLA_UN                 object\n",
      "IDITEM                    int64\n",
      "IDENTIFICACAO            object\n",
      "DESCRICAO                object\n",
      "IDGRUPOITEM               int64\n",
      "IDATENDREQMATITEM         int64\n",
      "IDGRUPOPAI              float64\n",
      "DESC_GRUPO               object\n",
      "EMPREGADO_ATEND          object\n",
      "IDCONTACDC              float64\n",
      "IDCONTACAR               object\n",
      "DESCRICAOCONTACDC        object\n",
      "CLASSIFICACAOCDC         object\n",
      "DESCRICAOCONTACAR        object\n",
      "CLASSIFICACAOCAR         object\n",
      "ESTOQUEFECHADO          float64\n",
      "CUSTOMEDIO              float64\n",
      "QUANTLOTE               float64\n",
      "QUANT_ATEND_LOTE        float64\n",
      "NUMLOTE                  object\n",
      "IDREQMATTENANT          float64\n",
      "dtype: object\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Verificação de Tipos ---\n",
    "print(f\"[{time.strftime('%H:%M:%S')}] --- INICIANDO VERIFICAÇÃO DE TIPOS ---\")\n",
    "verificar_tipos_dados(dfs_carregados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# --- 2. Exportação para Parquet ---\\nprint(f\"[{time.strftime(\\'%H:%M:%S\\')}] --- INICIANDO EXPORTAÇÃO PARQUET ---\")\\n\\nfor nome, df in dfs_carregados.items():\\n    salvar_parquet(df, nome)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# --- 2. Exportação para Parquet ---\n",
    "print(f\"[{time.strftime('%H:%M:%S')}] --- INICIANDO EXPORTAÇÃO PARQUET ---\")\n",
    "\n",
    "for nome, df in dfs_carregados.items():\n",
    "    salvar_parquet(df, nome)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pipeline finalizada em 5446.90 segundos ---\n",
      "--- Pipeline finalizada em 90.78 minutos ---\n"
     ]
    }
   ],
   "source": [
    "total_pipeline_time = time.time() - pipeline_start\n",
    "print(f\"--- Pipeline finalizada em {total_pipeline_time:.2f} segundos ---\")\n",
    "print(f\"--- Pipeline finalizada em {total_pipeline_time / 60:.2f} minutos ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Usado para transformar a lista de DataFrames em variáveis globais\n",
    "for nome, df in dfs_carregados.items():\n",
    "    globals()[nome] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Staging - Bronze - Dados Brutos tipos indefinidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:37:32] INICIANDO CARGA STAGING (COPY FROM)\n",
      "[09:37:32] Preparando tabela useall_staging.itens_staging | Linhas: 15845\n",
      "[09:37:32] Iniciando COPY para useall_staging.itens_staging\n",
      "[09:37:32] [OK] Tabela useall_staging.itens_staging carregada com sucesso\n",
      "[09:37:32] Preparando tabela useall_staging.unidades_staging | Linhas: 59\n",
      "[09:37:32] Iniciando COPY para useall_staging.unidades_staging\n",
      "[09:37:32] [OK] Tabela useall_staging.unidades_staging carregada com sucesso\n",
      "[09:37:32] Preparando tabela useall_staging.cidades_staging | Linhas: 6141\n",
      "[09:37:33] Iniciando COPY para useall_staging.cidades_staging\n",
      "[09:37:33] [OK] Tabela useall_staging.cidades_staging carregada com sucesso\n",
      "[09:37:33] Preparando tabela useall_staging.solcompra_staging | Linhas: 321\n",
      "[09:37:33] Iniciando COPY para useall_staging.solcompra_staging\n",
      "[09:37:33] [OK] Tabela useall_staging.solcompra_staging carregada com sucesso\n",
      "[09:37:33] Preparando tabela useall_staging.filiais_staging | Linhas: 23\n",
      "[09:37:33] Iniciando COPY para useall_staging.filiais_staging\n",
      "[09:37:33] [OK] Tabela useall_staging.filiais_staging carregada com sucesso\n",
      "[09:37:33] Preparando tabela useall_staging.empresas_staging | Linhas: 7\n",
      "[09:37:33] Iniciando COPY para useall_staging.empresas_staging\n",
      "[09:37:33] [OK] Tabela useall_staging.empresas_staging carregada com sucesso\n",
      "[09:37:33] Preparando tabela useall_staging.expedição_staging | Linhas: 33492\n",
      "[09:37:33] Iniciando COPY para useall_staging.expedição_staging\n",
      "[09:37:34] [OK] Tabela useall_staging.expedição_staging carregada com sucesso\n",
      "[09:37:34] Preparando tabela useall_staging.clientesfornecedore_staging | Linhas: 34040\n",
      "[09:37:34] Iniciando COPY para useall_staging.clientesfornecedore_staging\n",
      "[09:37:34] [OK] Tabela useall_staging.clientesfornecedore_staging carregada com sucesso\n",
      "[09:37:34] Preparando tabela useall_staging.requisicoes_staging | Linhas: 677954\n",
      "[09:37:35] Iniciando COPY para useall_staging.requisicoes_staging\n",
      "[09:37:48] [OK] Tabela useall_staging.requisicoes_staging carregada com sucesso\n",
      "[09:37:48] Preparando tabela useall_staging.estoque_staging | Linhas: 132381\n",
      "[09:37:48] Iniciando COPY para useall_staging.estoque_staging\n",
      "[09:37:50] [OK] Tabela useall_staging.estoque_staging carregada com sucesso\n",
      "[09:37:50] Preparando tabela useall_staging.atendimentodereq_staging | Linhas: 517766\n",
      "[09:37:50] Iniciando COPY para useall_staging.atendimentodereq_staging\n",
      "[09:38:02] [OK] Tabela useall_staging.atendimentodereq_staging carregada com sucesso\n",
      "[09:38:02] --------------------------------------------------\n",
      "[09:38:02] 11 tabelas staging criadas com sucesso.\n",
      "[09:38:02] PROCESSO FINALIZADO\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import time\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "\n",
    "DB_URL = \"postgresql+psycopg2://postgres:4102@localhost:5432/SETUP\"\n",
    "\n",
    "PG_CONN_INFO = {\n",
    "    \"dbname\": \"SETUP\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"4102\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432,\n",
    "}\n",
    "\n",
    "SCHEMA = \"useall_staging\"\n",
    "\n",
    "# ---------------------------------------\n",
    "\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "# garante schema\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {SCHEMA}\"))\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def log(msg: str):\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] {msg}\")\n",
    "\n",
    "\n",
    "def copy_df_to_postgres(df, schema: str, table: str):\n",
    "    import psycopg2\n",
    "    import io\n",
    "\n",
    "    buffer = io.StringIO()\n",
    "    df.to_csv(\n",
    "        buffer,\n",
    "        index=False,\n",
    "        header=False,\n",
    "        sep=\"\\t\",\n",
    "        na_rep=\"\\\\N\"\n",
    "    )\n",
    "    buffer.seek(0)\n",
    "\n",
    "    conn = psycopg2.connect(**PG_CONN_INFO)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    sql = f\"\"\"\n",
    "        COPY {schema}.{table}\n",
    "        FROM STDIN\n",
    "        WITH (FORMAT CSV, DELIMITER E'\\t', NULL '\\\\N')\n",
    "    \"\"\"\n",
    "\n",
    "    cur.copy_expert(sql, buffer)\n",
    "\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "\n",
    "tabelas_criadas = 0\n",
    "dfs_nao_encontrados = []\n",
    "\n",
    "log(\"INICIANDO CARGA STAGING (COPY FROM)\")\n",
    "\n",
    "for tarefa in tarefas:\n",
    "    df_nome = tarefa[\"nome\"]\n",
    "    df = globals().get(df_nome)\n",
    "\n",
    "    if df is None or df.empty:\n",
    "        dfs_nao_encontrados.append(df_nome)\n",
    "        continue\n",
    "\n",
    "    tabela = df_nome.replace(\"dfuseall\", \"\") + \"_staging\"\n",
    "    tabela = tabela.lower()\n",
    "\n",
    "    log(f\"Preparando tabela {SCHEMA}.{tabela} | Linhas: {len(df)}\")\n",
    "\n",
    "    # 1️⃣ cria estrutura (DDL leve)\n",
    "    with engine.connect() as conn:\n",
    "        df.head(0).to_sql(\n",
    "            name=tabela,\n",
    "            con=conn,\n",
    "            schema=SCHEMA,\n",
    "            if_exists=\"replace\",\n",
    "            index=False\n",
    "        )\n",
    "        conn.commit()\n",
    "\n",
    "    log(f\"Iniciando COPY para {SCHEMA}.{tabela}\")\n",
    "\n",
    "    # 2️⃣ carga pesada via COPY\n",
    "    copy_df_to_postgres(df, SCHEMA, tabela)\n",
    "\n",
    "    log(f\"[OK] Tabela {SCHEMA}.{tabela} carregada com sucesso\")\n",
    "\n",
    "    tabelas_criadas += 1\n",
    "\n",
    "# ---------------- FINAL ----------------\n",
    "\n",
    "log(\"--------------------------------------------------\")\n",
    "\n",
    "if tabelas_criadas == 0:\n",
    "    log(\"Nenhuma tabela staging foi criada.\")\n",
    "    log(\"DataFrames não encontrados:\")\n",
    "    for nome in dfs_nao_encontrados:\n",
    "        log(f\" - {nome}\")\n",
    "else:\n",
    "    log(f\"{tabelas_criadas} tabelas staging criadas com sucesso.\")\n",
    "\n",
    "log(\"PROCESSO FINALIZADO\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silver definindo tipos automaticamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:38:02] Profiling useall_staging.estoque_staging -> useall_silver.estoque_silver\n",
      "[09:38:04] Profiling useall_staging.atendimentodereq_staging -> useall_silver.atendimentodereq_silver\n",
      "[09:38:07] Profiling useall_staging.itens_staging -> useall_silver.itens_silver\n",
      "[09:38:07] Profiling useall_staging.unidades_staging -> useall_silver.unidades_silver\n",
      "[09:38:07] Profiling useall_staging.cidades_staging -> useall_silver.cidades_silver\n",
      "[09:38:07] Profiling useall_staging.solcompra_staging -> useall_silver.solcompra_silver\n",
      "[09:38:07] Profiling useall_staging.filiais_staging -> useall_silver.filiais_silver\n",
      "[09:38:07] Profiling useall_staging.empresas_staging -> useall_silver.empresas_silver\n",
      "[09:38:08] Profiling useall_staging.expedição_staging -> useall_silver.expedição_silver\n",
      "[09:38:09] Profiling useall_staging.clientesfornecedore_staging -> useall_silver.clientesfornecedore_silver\n",
      "[09:38:11] Profiling useall_staging.requisicoes_staging -> useall_silver.requisicoes_silver\n",
      "[09:38:14] Criando tabela silver useall_silver.estoque_silver\n",
      "[09:38:14] Criando tabela silver useall_silver.atendimentodereq_silver\n",
      "[09:38:14] Criando tabela silver useall_silver.itens_silver\n",
      "[09:38:14] Criando tabela silver useall_silver.unidades_silver\n",
      "[09:38:14] Criando tabela silver useall_silver.cidades_silver\n",
      "[09:38:14] Criando tabela silver useall_silver.solcompra_silver\n",
      "[09:38:14] Criando tabela silver useall_silver.filiais_silver\n",
      "[09:38:14] Criando tabela silver useall_silver.empresas_silver\n",
      "[09:38:14] Criando tabela silver useall_silver.expedição_silver\n",
      "[09:38:14] Criando tabela silver useall_silver.clientesfornecedore_silver\n",
      "[09:38:14] Criando tabela silver useall_silver.requisicoes_silver\n",
      "[09:38:14] Carregando dados em useall_silver.estoque_silver\n",
      "[09:38:15] [OK] useall_silver.estoque_silver carregada\n",
      "[09:38:15] Carregando dados em useall_silver.atendimentodereq_silver\n",
      "[09:38:21] [OK] useall_silver.atendimentodereq_silver carregada\n",
      "[09:38:21] Carregando dados em useall_silver.itens_silver\n",
      "[09:38:21] [OK] useall_silver.itens_silver carregada\n",
      "[09:38:21] Carregando dados em useall_silver.unidades_silver\n",
      "[09:38:21] [OK] useall_silver.unidades_silver carregada\n",
      "[09:38:21] Carregando dados em useall_silver.cidades_silver\n",
      "[09:38:21] [OK] useall_silver.cidades_silver carregada\n",
      "[09:38:21] Carregando dados em useall_silver.solcompra_silver\n",
      "[09:38:21] [OK] useall_silver.solcompra_silver carregada\n",
      "[09:38:21] Carregando dados em useall_silver.filiais_silver\n",
      "[09:38:21] [OK] useall_silver.filiais_silver carregada\n",
      "[09:38:21] Carregando dados em useall_silver.empresas_silver\n",
      "[09:38:21] [OK] useall_silver.empresas_silver carregada\n",
      "[09:38:21] Carregando dados em useall_silver.expedição_silver\n",
      "[09:38:21] [OK] useall_silver.expedição_silver carregada\n",
      "[09:38:21] Carregando dados em useall_silver.clientesfornecedore_silver\n",
      "[09:38:22] [OK] useall_silver.clientesfornecedore_silver carregada\n",
      "[09:38:22] Carregando dados em useall_silver.requisicoes_silver\n",
      "[09:38:30] [OK] useall_silver.requisicoes_silver carregada\n",
      "[09:38:30] --------------------------------------------------\n",
      "[09:38:30] PROCESSO FINALIZADO\n"
     ]
    }
   ],
   "source": [
    "silver_SCHEMA = \"useall_silver\"\n",
    "SAMPLE_LIMIT = 50000\n",
    "\n",
    "# Garante schema\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {silver_SCHEMA}\"))\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Detecta formato de data\n",
    "def is_date_series(s: pd.Series):\n",
    "    sample = s.dropna().astype(str).head(50)\n",
    "    formats = [\n",
    "        \"%Y-%m-%d\",\n",
    "        \"%Y-%m-%d %H:%M:%S\",\n",
    "        \"%Y-%m-%dT%H:%M:%S\",\n",
    "        \"%d/%m/%Y\",\n",
    "        \"%d/%m/%Y %H:%M:%S\",\n",
    "    ]\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            pd.to_datetime(sample, format=fmt)\n",
    "            return fmt\n",
    "        except:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "# Inferência de tipo\n",
    "def infer_column_type_final(series: pd.Series) -> dict:\n",
    "    s = series.dropna()\n",
    "    if s.empty:\n",
    "        return {\"type\": \"text\"}\n",
    "\n",
    "    # BOOLEAN lógico\n",
    "    if s.astype(str).isin([\"0\",\"1\",\"true\",\"false\",\"True\",\"False\"]).all():\n",
    "        return {\"type\": \"boolean\"}\n",
    "\n",
    "    # DATE / TIMESTAMP\n",
    "    date_fmt = is_date_series(s)\n",
    "    if date_fmt:\n",
    "        return {\"type\": \"timestamp\", \"format\": date_fmt}\n",
    "\n",
    "    # INTEGER\n",
    "    if s.astype(str).str.fullmatch(r\"-?\\d+\").all():\n",
    "        return {\"type\": \"bigint\"}\n",
    "\n",
    "    # DECIMAL\n",
    "    if s.astype(str).str.fullmatch(r\"-?\\d+(\\.\\d+)?\").all():\n",
    "        return {\"type\": \"numeric(18,4)\"}\n",
    "\n",
    "    return {\"type\": \"text\"}\n",
    "\n",
    "# Busca tabelas staging\n",
    "staging_tables = pd.read_sql(f\"\"\"\n",
    "SELECT table_name\n",
    "FROM information_schema.tables\n",
    "WHERE table_schema = '{SCHEMA}' AND table_type='BASE TABLE'\n",
    "\"\"\", engine)[\"table_name\"].tolist()\n",
    "\n",
    "# Função nome silver\n",
    "def silver_table_name(staging_table: str) -> str:\n",
    "    return staging_table.replace(\"_staging\", \"_silver\") if staging_table.endswith(\"_staging\") else staging_table + \"_silver\"\n",
    "\n",
    "# Monta dicionário de metadata\n",
    "schema_silver = {}\n",
    "\n",
    "for staging_table in staging_tables:\n",
    "    silver_table = silver_table_name(staging_table)\n",
    "    log(f\"Profiling {SCHEMA}.{staging_table} -> {silver_SCHEMA}.{silver_table}\")\n",
    "\n",
    "    df_sample = pd.read_sql(f'SELECT * FROM {SCHEMA}.\"{staging_table}\" LIMIT {SAMPLE_LIMIT}', engine)\n",
    "    schema_silver[silver_table] = {\n",
    "        \"staging_table\": staging_table,\n",
    "        \"columns\": {col: infer_column_type_final(df_sample[col]) for col in df_sample.columns}\n",
    "    }\n",
    "\n",
    "# Cria cast SQL\n",
    "def generate_cast_sql(col, meta):\n",
    "    col_sql = f'\"{col}\"'\n",
    "    col_txt = f'{col_sql}::text'\n",
    "\n",
    "    if meta[\"type\"] == \"boolean\":\n",
    "        return f\"\"\"\n",
    "        CASE\n",
    "            WHEN lower({col_txt}) IN ('1','true','sim','s','y','yes') THEN true\n",
    "            WHEN lower({col_txt}) IN ('0','false','nao','n','no') THEN false\n",
    "            ELSE NULL\n",
    "        END AS \"{col}\"\n",
    "        \"\"\"\n",
    "\n",
    "    if meta[\"type\"] == \"timestamp\":\n",
    "        fmt = meta.get(\"format\")\n",
    "        if fmt:\n",
    "            return f\"\"\"\n",
    "            CASE\n",
    "                WHEN {col_sql} IS NULL OR {col_txt} = '' THEN NULL\n",
    "                ELSE to_timestamp({col_txt}, '{fmt}')\n",
    "            END AS \"{col}\"\n",
    "            \"\"\"\n",
    "        else:\n",
    "            return f\"\"\"\n",
    "            CASE\n",
    "                WHEN {col_sql} IS NULL OR {col_txt} = '' THEN NULL\n",
    "                ELSE {col_sql}::timestamp\n",
    "            END AS \"{col}\"\n",
    "            \"\"\"\n",
    "\n",
    "    if meta[\"type\"] in (\"bigint\",\"numeric(18,4)\"):\n",
    "        return f\"\"\"\n",
    "        CASE\n",
    "            WHEN {col_txt} ~ '^-?\\\\d+(\\\\.\\\\d+)?$' THEN {col_txt}::{meta[\"type\"]}\n",
    "            ELSE NULL\n",
    "        END AS \"{col}\"\n",
    "        \"\"\"\n",
    "\n",
    "    return f'{col_sql}::text AS \"{col}\"'\n",
    "\n",
    "# Gera CREATE TABLE\n",
    "def generate_create_table(schema, table, columns: dict):\n",
    "    cols = \",\\n  \".join(f'\"{col}\" {meta[\"type\"]}' for col, meta in columns.items())\n",
    "    return f\"\"\"\n",
    "    DROP TABLE IF EXISTS {schema}.\"{table}\";\n",
    "    CREATE TABLE {schema}.\"{table}\" (\n",
    "      {cols}\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "# Cria tabelas silver\n",
    "for silver_table, meta in schema_silver.items():\n",
    "    log(f\"Criando tabela silver {silver_SCHEMA}.{silver_table}\")\n",
    "    ddl = generate_create_table(silver_SCHEMA, silver_table, meta[\"columns\"])\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(ddl))\n",
    "\n",
    "# Gera INSERT\n",
    "def generate_insert_cast(staging_schema, silver_schema, staging_table, silver_table, columns):\n",
    "    selects = \",\\n\".join(generate_cast_sql(col, meta) for col, meta in columns.items())\n",
    "    return f\"\"\"\n",
    "    INSERT INTO {silver_schema}.\"{silver_table}\"\n",
    "    SELECT\n",
    "      {selects}\n",
    "    FROM {staging_schema}.\"{staging_table}\";\n",
    "    \"\"\"\n",
    "\n",
    "# Carrega dados\n",
    "for silver_table, meta in schema_silver.items():\n",
    "    staging_table = meta[\"staging_table\"]\n",
    "    columns = meta[\"columns\"]\n",
    "    log(f\"Carregando dados em {silver_SCHEMA}.{silver_table}\")\n",
    "    sql = generate_insert_cast(SCHEMA, silver_SCHEMA, staging_table, silver_table, columns)\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            conn.execute(text(sql))\n",
    "        log(f\"[OK] {silver_SCHEMA}.{silver_table} carregada\")\n",
    "    except Exception as e:\n",
    "        log(f\"[ERRO] {silver_SCHEMA}.{silver_table} -> {e}\")\n",
    "\n",
    "log(\"--------------------------------------------------\")\n",
    "log(\"PROCESSO FINALIZADO\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold - Adicionando novas colunas e agregando valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "ALTER TABLE USEALL_SILVER.REQUISICOES_SILVER\n",
    "ADD COLUMN DESC_STATUS TEXT;\n",
    "\n",
    "UPDATE USEALL_SILVER.REQUISICOES_SILVER\n",
    "SET\n",
    "\tDESC_STATUS = CASE \"STATUS\"\n",
    "\t\tWHEN 0 THEN 'Digitado'\n",
    "\t\tWHEN 1 THEN 'Aberto'\n",
    "\t\tWHEN 3 THEN 'Cancelado'\n",
    "\t\tWHEN 10 THEN 'Parcial'\n",
    "\t\tWHEN 11 THEN 'Atendido'\n",
    "\t\tELSE 'Desconhecido'\n",
    "\tEND;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
